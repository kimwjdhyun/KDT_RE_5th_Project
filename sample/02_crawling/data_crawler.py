"""
ì›¹ í¬ë¡¤ë§ ìƒ˜í”Œ ì½”ë“œ
Selenium + BeautifulSoup ì‚¬ìš©

ì´ íŒŒì¼ì€ ì°¸ê³ ìš© ìƒ˜í”Œì…ë‹ˆë‹¤.
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import pandas as pd
import time

print("="*60)
print("ì›¹ í¬ë¡¤ë§ ìƒ˜í”Œ")
print("="*60)

# ==================== Chrome ì„¤ì • ====================
chrome_options = Options()
chrome_options.add_argument('--headless')  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('user-agent=Mozilla/5.0')

print("\n[1] ì›¹ë“œë¼ì´ë²„ ì´ˆê¸°í™”...")

try:
    from webdriver_manager.chrome import ChromeDriverManager
    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=chrome_options
    )
    print("âœ… ì›¹ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì™„ë£Œ")
except ImportError:
    print("âš ï¸ webdriver-manager ì„¤ì¹˜ í•„ìš”")
    print("   pip install webdriver-manager")
    exit(1)

# ==================== í¬ë¡¤ë§ ì˜ˆì œ ====================

def example_crawl():
    """ê°„ë‹¨í•œ í¬ë¡¤ë§ ì˜ˆì œ"""
    print("\n[2] ê³µê³µë°ì´í„° í¬í„¸ ì ‘ì†...")
    
    try:
        url = "https://www.data.go.kr/index.do"
        driver.get(url)
        time.sleep(3)
        
        # í˜ì´ì§€ ì œëª© ê°€ì ¸ì˜¤ê¸°
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        title = soup.find('title')
        print(f"âœ… í˜ì´ì§€ ì œëª©: {title.text if title else 'N/A'}")
        
        # ê²€ìƒ‰ì°½ ì°¾ê¸° (ì˜ˆì‹œ)
        try:
            search_box = driver.find_element(By.ID, "header-query")
            print("âœ… ê²€ìƒ‰ì°½ ë°œê²¬")
        except:
            print("âš ï¸ ê²€ìƒ‰ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return True
        
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return False

# ==================== ì‹¤í–‰ ====================
try:
    example_crawl()
    
    print("\n" + "="*60)
    print("âœ… í¬ë¡¤ë§ ì™„ë£Œ!")
    print("="*60)
    print("\nğŸ’¡ ì‹¤ì œ ì‚¬ìš©ì‹œ:")
    print("  1. crawler_config.pyì—ì„œ API í‚¤ ì„¤ì •")
    print("  2. í¬ë¡¤ë§ ëŒ€ìƒ URL í™•ì¸")
    print("  3. ì½”ë“œ ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©")
    
except Exception as e:
    print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

finally:
    driver.quit()
    print("\nâœ… ë¸Œë¼ìš°ì € ì¢…ë£Œ")
